# Лекция 4

## Встроенные функции сортировки

```julia
sort
sort!
sortperm
sortperm!
issorted
```

## Сортировки квадратичной сложности

Вспомним сначала два простых алгоритма сортировки квадратичной сложности - так называемые пузырьковую сортировка и сортировка вставками.

- Пузырьковая сортировка

```julia
function bubble_sort!(a)
    n = length(a)
    for k in 1:n-1
        istranspose = false
        for i in 1:n-k
            if a[i]>a[i+1]
                a[i], a[i+1] = a[i+1], a[i]
                istranspose = true
            end
        end
        if istranspose == false
            break
        end
    end
    return a
end
```
- Сортировка вставками

```julia
function insert_sort!(vector)
    n = 1
    # ИНВАРИАНТ: срез vector[1:n] - отсортирован
    while n < length(vector) 
        n += 1
        i = n
        while i > 1 && vector[i-1] > vector[i]
            vector[i], vector[i-1] = vector[i-1], vector[i]
            i -= 1
        end
        #УТВ: vector[1]<=...<=vector[n]
    end
    return vector
end
```

Очевидно, что в наихудшем случае данные алгоритмы имеют асимптотическую оценку сложности $O(N^2)$, где $N$-длина массива. 

Также существуют так называемые быстрые алгоритмы сортировки, с асимптотической оценкой сложности $O(N\log N)$. 

Однако известны также модификации рассмотренных алгоритмов квадратичной сложности, которые хотя и не изменяют их асимптотическую оценку, но на практике делают их вполне конкурентоно способными с быстрыми алгоритмами. 

В первую очередь, это так называемые алгоритмм сортировки "расчесыванием", который есть модификация пузырьковой сортировки, и алгоритм Шелла, который есть модификация сортировки вставками.

## Высоко эффективные алгоритмы сортировки Шелла и "расчесыванием" (квадратичной сложности)

Основная проблема алгоритма пузырьковой сортировки и алгоритма вставками состоит не в том, что они требуют $O(N^2)$ операций сравнения, а в том, что для их реализации может потребоваться столько же перестановок соседних элементов массива, т.к. перестановки элементов значительно более затратная процедура по сравнению с операцией сравнения.

Поэтому, если каким-либо образом удастся уменьшить количество таких перстановок, то это очень существенно сократит время всей сортировки.

Зададимся вопросом, когда при выполнении указанных сортировок требуется наибольшее количество перестановок. Ответ, очевидно, будет следующим, - если в начале исходного массива было много "больших" чисел, потому, что тогда эти числа придется многократно обменивать с соедними до тех пор, пока они не окажутся на своих местах ближе к концу массива.

Число таких обменов можно попытаться уменьшить, если вначале сравнивать и, при нобходимости, менять местами не соседние  элементы масива, а только отстоящие друг от друга на значительно большее расстояние. Затем это расстояние надо будет уменьшить и повторить ту же процедуру частичной сортировки массива с самого его начала. Последнее надо будет повторять до тех пор, пока расстояние между соседними сравниваемыми элементами не станет равным 1. В результате значительной части "большие" элементы из начала массива переместятся в его конец значительно быстрее в сравнении с тем, как если бы с самого начала сравнивались лишь непосредственно соседние элементы массива.

Это общая идея повышения эффективности рассмотренных ранее алгоритмов сортирвки "пузырьком" и вставками. При этом в обоих случаях первоначальное расстояние между сравниваемыми элементами массива следует брать равным длине массива (т.е. на первом шаге будут сравниваться только первый и последний элементы массива).

В случае классической сортировки Шелла, базирующейся на сортировке вставками, в классическом её варианте, это расстояние каждый раз уменьшается вдвое (приблизительно). Причем, когда будет достигнуто равенство единице этого расстояния, то массив, очевидно, окажется отсортированным.

В случае же алгоритма сортировки "расчесыванием", базирующегося на "пузырьковой" сортировке, расстояние между ближайшими сравниваемыми элементами каждый раз уменьшается путем деления последнего его значения на некоторый коэффициент, больший 1 (эмпирически установлено, что этот коэффициент лучше всего взять равным приблизительно 1.247). Однако в отличие от сортировки Шелла, при сортировке  "расчесыванием", когда это расстояние окажется равным 1, остается в точности не известно, сколько же еще раз надо пройти массив, сравнивая соседние элементы (как это делается в "пузырьковой" сортировке), чтобы он оказался полностью отсорированным. Но это число будет уже совсем небольшим (обычно остается сделать еще всего несколько проходов).

Подробно сортировка Шелла и сортировка "прочесыванием" будут рассмотрены на практическом занятии.

## Эффективная сортировка с асимптотической оценкой сложности - $O(N)$ (сортировка "за линейное время")

```julia
function calc_sort!(A::AbstractVector{<:Integer})
    min_val, max_val = extrema(A)
    num_val = zeros(Int, max_val-min_val+1) # - число всех возможных значений
    for val in A
        num_val[val-min_val+1] += 1
    end  
    k = 0
    for (i, num) in enumerate(num_val)
        A[k+1:k+num] .= min_val+i-1
        k += num
    end
    return A
end
```

Высокая эффективность данной сортирвки обусловлена тем, что при таком способе сортирови нет надобности в перемещениях элементов массива. Однако таким способом очевидно можно отсортировать не лбой массив. Можно показать, что сортировки, основанные на перемещениях элементов массива не могут иметь оценку сложности луче, чем $O(Nlog(N))$. Поэтому алгоритмы с такой оценкой сложности называются быстрыми. 

## Быстрая сортировка слияниями

- Основная вспомогательная процедура сортировки слияниями
```julia
"""
merge!(a1, a2, a3)::Nothing

    ДАНО: length(a3) == length(a1)+length(a2) && issorted(a1) && issorted(a2)
    
    РЕЗУЛЬТАТ: issorted(a3)
"""
@inline function Base.merge!(a1, a2, a3)::Nothing # @inline - делает функцию "встраиваемой", т.е. во время компиляции ее тело будет встроено непосредственно в код вызывающей функции (за счет этого происходит экономия на времени, затрачиваемым на вызов функции; это время очень небольшое, но тем не менее)
    i1, i2, i3 = 1, 1, 1
    @inbounds while i1 <= length(a1) && i2 <= length(a2) # @inbounds - передотвращает проверки выхода за пределы массивов
        if a1[i1] < a2[i2]
            a3[i3] = a1[i1]
            i1 += 1
        else
            a3[i3] = a2[i2]
            i2 += 1
        end
        i3 += 1
    end
    @inbounds if i1 > length(a1)
        a3[i3:end] .= @view(a2[i2:end]) # Если бы тут было: a3[i3:end] = @view(a2[i2:end]), то это привело бы к лишним аллокациям (к созданию промежуточного массива)
    else
        a3[i3:end] .= @view(a1[i1:end])
    end
    nothing
end
```

- Алгоритм сортировки слияниями

```julia
function merge_sort!(a)
    b = similar(a) # - вспомогательный массив того же размера и типа, что и массив a
    N = length(a)
    n = 1 # n - текущая длина блоков
    @inbounds while n < N
        K = div(N,2n) # - число имеющихся пар блоков длины n
        for k in 0:K-1
            merge!(@view(a[(1:n).+k*2n]), @view(a[(n+1:2n).+k*2n]), @view(b[(1:2n).+k*2n]))
        end
        if N - K*2n > n # - осталось еще смержить блок длины n и более короткий остаток
            merge!(@view(a[(1:n).+K*2n]), @view(a[K*2n+n+1:end]), @view(b[K*2n+1:end]))
        elseif 0 < N - K*2n <= n # - оставшуюся короткую часть мержить не с чем
            b[K*2n+1:end] .= @view(a[K*2n+1:end])
        end
        a, b = b, a
        n *= 2
    end
    if isodd(log2(n)) # - если цикл был выполнен нечетное число раз, то b - это исходная ссылка на массив (на внешний массив), и a - это ссылка на вспомогательный массив (локальный)
        b .= a # b = copy(a) - это было бы не то же самое, т.к. при этом получилась бы ссылка на новый массив, который создает функция copy
        a = b
    end
    return a # - исходная ссылка на внешний массив (проверить, что это так, можно с помощью ===)
end
```


## Тип данных "куча"

**Куча** представляет собой двоичную иерархическую структуру, в которой значение каждого из двух дочерних элементов меньше (больше) значения родительского элемента.

Если на вершине кучи находится максимальное значение, то она называется максимальной. 

В противном случае, есле на вершине кучи находится минимальное значение, то она называется минимальной.

Не надо путать понятие кучи с упорядоченным двоичным деревом, в котором для лбой вершины верно, что все элементы, ассоциированные с лквым поддеревом, меньше элемента ассоциированного с данной вершиной, а все элементы, ассоциированные с правым поддеревом болше этого элемента.

### Реализация кучи на базе массива

Как правило кучу реализуют на базе обычного массива.

Массив `heap` имеет структуру **кучи** (**максимальной** кучи), если  для каждого `i`-го его элемента верно, что:
- `heap[i] >= heap[2i]`
- `heap[i] >= heap[2i+1]`

разумеется, индекс `i` здесь не должен превосходить `length(heap)÷2`. 

Преобразовать произвольный массива в максимальную кучу можно за $O(N)$ действий.

```julia
function heap!(array)
    N = length(array)
    for i in 1:N÷2
        if array[i] < array[2i]
            array[i], array[2i] = array[2i], array[i]
        end
        
        if 2i+1 <= N && array[i] < array[2i+1]
            array[i], array[2i+1] = array[2i+1], array[i]
        end
    end
    return array
end
```

Соответсвенно, если при всех возможных `i` выполняются условия
 - `heap[i] <= heap[2i]`
 - `heap[i] <= heap[2i+1]`
 
то массив `heap` имеет структуру **минимальной** кучи.

### Перемещение элемента на место, соответствующее его приоритету

Допустим, что имеется только один единственный элемент в куче, который стоит на позиции (в общем случае - `i`-ой), не соответствующей его приоритету. 

Такая ситуация может возникать, например, при добавлении/удалинии элемента в кучу. А также, если при решении какой-либо задачи, на каком-то шаге произошло изменение значения приоритета какого-то одного элемента кучи. 

Задача состоит в том, что бы переместить этот элемент на нужную позицию, восстановив требуемую структуру кучи.

Например, может потребоваться "понизить" элемент с индексом `index`, перемещая его ближе к концу кучи до тех пор, пока он не займет свое "правильное" место в массиве ("куче"), соответсвующее его значению.


Это можно делать с помощью одной из следующих двух функций, сложность каждой из которых оценивается как $O(log(N))$.

```julia
"""
    down_first!(heap::AbstractVector)::Nothing

Перемещает первый элемент массива ближе к концу кучи, пока он не займет свое "правильное" место в куче.
"""
function down_first!(heap::AbstractVector)::Nothing
    index = 1
    N = length(heap)
    while index < N÷2
        if heap[index] < heap[2index]
            heap[index], heap[2index] = heap[2index], heap[index]
        end
        if 2index+1 <= N && heap[index] < heap[2index+1]
            heap[index], heap[2index+1] = heap[2index+1], heap[index]
        end
        index *= 2
    end
end
```

## Пирамидальная сортировка

Пусть $heap$ - произвольный вектор длины $N$.

Процедура сортировки состоит из следующих шагов.

1. Преобразуем исходный массив в кучу (с помощью функции heap!), на что потребуется $O(N)$ операций.

2. Поменяем местами первый элемент массива (после предыдущего шага он будет максималным) с последним (тем самым последний элемент массива окажется на "своем" окончательном месте), и переместим новый первый элемент массива на "правильное" место в куче. С использованием функции `down!` на это потребуется $O(\log N)$ элементарных операций.

4. Длину сортируемой части массива уменьшим на 1 и перейдем к пункту 2, и т.д. пока длина сортируемой части станет раной 3 (первые три элемента кучи всегда отсортированы).

Таким образом, сложность пирамидальной сортировки имеет оценку $O(N \log N)$. 

```julia
function heap_sort!(heap::AbstractVector)
    heap = heap!(heap) 
    # здесь heap! - это именно функция, преобразующая массивив в максимальную кучу, а не конструктор типа Heap!
    N = length(heap)  
    #ИНВАРИАНТ: heap[1:N] - это максимальная куча && heap[N+1:end] - это отсортированная часть массива
    while N > 3
        heap[1], heap[N] = heap[N], heap[1]
        N -= 1
        down_first!(@view(heap[1:N])) 
    end
    return heap
end
```

## Быстрая сортировка Хоара с асимптотической оценкой сложности в среднем - $O(N\log(N))$

Алгоритм сортировки Хоара на практике является одним из самых эффективных алгоритмов сортировки, поэтому он даже называется алгоритмом быстрой сортировки. Однако для него оценка сложности $O(N\log(N))$ только в средне-статистическом смысле. В худшем случае этот алгоритм может выродиться в алгоритм квадратической сложности.

В основе быстрой сортировки лежит следующая вспомогательная процедура частичной сортировки.

Пусть имеется массив $A$ и значение одного из его элементов, равное $b$. Требуется переставить элементы в массиве $A$ так, чтобы в нем сначала следовали все элементы, меньшие $b$, затем - все, равные $b$, а затем - все, большие $b$.

Причем алгоритмическая сложность этой процедуры должна оцениваться как $O(N)$, где $N=length(A)$, и дополнительные массивы использоваться не должны.

Решим эту задачу с использованием метода инварианта цикла.

Напомним, что инвариантом цикла (с предусловием) называют утверждение (предикат), зависящее от фазовых переменных цикла (т.е. переменнных, которые могут изменяться в теле цикла), имеющее значение "истина" как до начала цикла, так и после любого числа его повторений.

Идея метода состоит в том, что для решения задачи сначала надо найти и сформулировать подходящий инвариант цикла, а затем уже на этой основе сконструировать соответствующий цикл.

Пусть величины $K, M, L$ (индексы массива $A$) такие, что

- $\forall i \in 1:K \ \ \ A[i]<b$
- $\forall i \in K+1:L \ \ \ A[i]==b$
- $\forall i \in M+1:N \ \ \ A[i]>b$

Эти три пункта, выполняемые одновременно, и будут составлять утверждение требуемого инварианта цикла. При этом в инварианте цикла ничего не утверждается про элементы массива для диапазона индексов $L+1:M$, этот диапазон индексов будет соответствовать еще не "обработаной" части массива. При чем в самом начале рассматриваемой процедуры частичной сортировки весь массив должен совпадать с этой "не обработанной" частью, а в конце процедуры "необработанная" часть должна будет получиться пустой.

Таким образом, искомая процедура частичной сортировки реализуется следующей фцнкцией.

```julia
function part_sort!(A, b)
    N = length(A)
    K=0
    L=0
    M=N
    #ИНВАРИАНТ: A[1:K] < b && A[K+1:L] == b && A[M+1:N] > b
    while L < M 
        if A[L+1] == b
            L += 1
        elseif A[L+1] > b
            A[L+1], A[M] = A[M], A[L+1]
            M -= 1
        else # if A[L+1] < b
            L += 1; K += 1
            A[L], A[K] = A[K], A[L]
        end
    end
    return K, M+1 
    # 1:K и M+1:N - эти диапазоны индексов определяют ещё не 
    # отсортированные части массива A
end
```

Теперь с использованием этой вспомогательной процедуры массив может быть отсортирован рекурсивно следующим образом.

```julia
function quick_sort!(A)
    if isempty(A)
        return A
    end
    N = length(A)
    K, M = part_sort!(A, A[rand(1:N)]) # - "базовый" элемент массива выбирается случайнам образом
    quick_sort!(@view A[1:K])
    quick_sort!(@view A[M:N])
    return A
end
```

Оценить сложность алгоритма быстрой сортироваки `quick_sort!` можно следующим образом. Поскольку каждый раз перед процедурой частичной сортировки part_sort! "базовый" элемент `b` массива `A` выбирается случайным образом, то можно считать, что **в среднем** размеры его частей `A[1:K]` и `A[M+1:N]`, подлежащих дальнейшей сортировке, но уже по отдельности, будут получаться приблизительно равными.

Для упрощения анализа условимся считать их равными $N/2$. Тогда всю процедуру сортировки можно будет представить двоичным деревом высоты $log_2(N)$ (каждый узел этого дерева фиксирует факт разделения рекурсивно сортируемой части массива на два подмассива равной длины). При этом корню этого дерева соответствует $N$ операций сранения, и каждому его последующему ярусу тоже сооттветствуют те же $N$ операций сравнения.

Таким образом, потребуется всего $N\log_2N$ операций, т.е. оценка сложности алгоритма сортировки в среднестатистическом смысле может быть выражена как $O(N\log(N))$.

## Порядковые статистики, алгоритм быстрого вычисления порядковых статистик

Пусть имеется числовой массив $А$. Его $k$-ой **порядковой статистикой** называется значение $k$-го элемента этого массива, которое получилось бы после реализации процедуры сортировки массива $A$.

Однако для вычисления $k$-ой порядковой статистики ($k$ считается фиксированным) вовсе не обязательно сортировать массив. Существует алгоритм вычисления этой величины, имеющий сложность всего $O(N)$, т.е. быстрый алгоритм.

В самом деле, если индекс $k$ задан, то требуемую процедуру вычисдения $k$-ой порядковой статистики легко получить из рассмотренного выше алгоритма Хоара быстрой сортировки. В самом деле, вычисление $k$-ой порядковой статистики от процедуры сортировки Хоара будет отличаться лишь тем, что для последующей после частичной сортирвки массива дальнейшая обработка массива должна бутет производиться лишь только над одной из двух полученных его частей, а именно, той из них, диапазон индексов которой включает заданное $k$.

В результате, первая частичная сортирвка даст $O(N)$ операций сравнения, вторая - $O(N/2)$, третья - $O(N/4)$ и т.д., что в сумме составит всего $O(N)$ операций.

**Замечание.** Минимальное и максмальное значения массива явяются его 1-ой и $N$-ой порядковыми статистиками, соответственно. Однако, хотя сложность их вычисления также оценивается как $O(N)$, их вычисление обычным способом потребует вдвое меньше сравнений (не говоря уже о том, что оно вовсе не потребует престановок элементов массива, что существенно более затратно по сравнению с просто опереацией сравнения).

```julia
function order_statistics!(A::AbstractVector{T}, i::Integer)::T where T
    function part_sort!(indexes_range::AbstractUnitRange, b)
        K, L, M = indexes_range[1]-1, indexes_range[begin]-1, indexes_range[end] # 0, 0, N
        #ИНВАРИАНТ: A[indexes_range[begin]:K] < b && A[K+1:L] == b && A[M+1:indexes_range[end]] > b
        while L < M 
            if A[L+1] == b
                L += 1
            elseif A[L+1] > b
                A[L+1], A[M] = A[M], A[L+1]
                M -= 1
            else # if A[L+1] < b
                L += 1; K += 1
                A[L], A[K] = A[K], A[L]
            end
        end    
        return indexes_range[begin]:K, M+1:indexes_range[end] 
        # - эти диапазоны индексов определяют ещё не отсортированные части массива A
    end

    function find(indexes_range)
        left_range, right_range = part_sort!(indexes_range, A[rand(indexes_range)]) 
        # - здесь "базовый" элемент массива выбирается случайным образом
        if i in left_range
            return find(left_range) 
        elseif i in right_range
            return find(right_range)
        else
            return A[i]
        end
    end

    find(firstindex(A):lastindex(A))
end

order_statistics(A, i) = order_statistics!(copy(A), i)
```

Здесь, в отличие от варианта функции `part_sort!(A, b)`, который использовался в сортировке Хоара, теперь, при вычислении `i`-ой порядковой статистики необходимо знать диапазон индексов той части массива, в которой следует искать эту порядковую статистику. Поэтому эта вспомогательная функция модифицирована таким образом, чтобы та часть исходного массива, которая должна подвергнуться процедуре частичной сортировки, опрделялась бы не сылкой на срез, а диапазоном соответсвующих индексов.

## Медиана массива

Если длина $N$ массива нечетная, то его медианой называется порядковая статистика с индексом $(N-1)/2$. В случае же четной длины массива его медианой можно считать среднее арифметическое двух порядковых статистик с индексами $N/2-1$ и $N/2+1$.

Поэтому алгоритм вычисления медианы массива также может основываться на быстром алгоритме вычисления порядковых статистик.

Медиана массива, наряду со средним (средним арифметическим) значением массива является важной статистической характеристикой содержащихся в нем данных. Например, эта характеристика более адекватно оценивает уровень доходов большинства граждан, нежели простое среднее арифметическое значение уровня доходов всех граждан.
