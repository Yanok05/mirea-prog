# Лекция 1

## Целые машинные числа конечной длины

Например

1. `Int64` - это кольцо вычетов по модулю `2^64` по симметричной системе остатков (`-9223372036854775808,...,-1,0,1,...,9223372036854775807`)
    Данный тип является основным типом целых чисел в языке Julia.

При этом

`2^63     = -9223372036854775808`

`2^63 - 1 =  9223372036854775807`

2. `UInt64` - это кольцо вычетов по модулю `2^64` по не симметричной системе остатков (`0, 1, 2,...,2^64-1`)


```julia
julia> typemin(Int)
-9223372036854775808

julia> typemax(Int)
9223372036854775807

julia> typemax(UInt)
0xffffffffffffffff # - это в 16-ричной системе 
```

Целые числа упорядочены, т.е. имееется операции `<`, `>`

В кольце вычетов невозможно определить порядок, согласованный с арифметическими операциями, например, сумма двух положительных элементов кольца вычетов может получиться отрицательной, а сумма двух отрицательных - положительным. Такая ситуация называется ПЕРЕПОЛНЕНИЕМ

Другие типы целых типов конечной длины используются для экономии памяти при работе с очень большими массивами.

## Тип BigInt

Данный реализован программно - это так называемая длинная арифметика. Длинная арифметика никогда не приводит к переполнению, но при этом она не сравнимо менее производительная по отношению к аппаратно реализованной арифметике.

Например

```julia
julia> 2^64 # - тип Int64
0

julia> BigInt(2)^64 # тип BigInt
18446744073709551616
```

## Функция digits

Эта функция позволяет получит массив из цифр целого числа лбого типа (и для любого основания системы счисления).

## Операции двоичного сдвига `>>`, `<<`

Эти операции выполняют сдвиг вправо (`>>`) и, соответственно, влево (`<<`) двоичного кода цeлого числа любого типа (за исключением `BigInt`). Например, с помощью этих операций можно реализовывать операции деления и умножения целого числа `2` с более высокой производительностью по отношению к стандартным арифметическим операциям.

## Функция bitstring для целых чисел

Функция `bitstring` формирует строку, содержащую биты внутреннего (машинного) представления числа (любого примитивного типа, включая целые типы и типы с плавающей точкой).

## Числа с плавающей точкой 


`знак*мантисса*2^порядок`


Нормализованная мантисса это двоичная дробь:

`1 <= мантисса < 2`

**Порядок** (двоичный) - это целое со знаком.

Для **Float64** (это основной тип с плавающей точкой):
- длина мантиссы `52` бита (но фактически длина `53` бита, т.к. первая цифра всегда `1`, но в память она не записывается);
- длина порядка `11` бит; 
- в памяти порядок представлен со смещением, т.е. в виде целого без знака, полцчаемому в результате прибавления к истинному значению порядка абсолютной величины его наименьшего значения (это обусловленно техническими причинами).

Примеры записи **значений** типа Float64 на языке Julia: `3.1415`, `-0.5`, `0.0`, `1.`, `1.1e-5`, `2e4`, `1.1E-5`, `2E4`, где, например, запись `1.1e-5` обозначает $1.1 \cdot 10^{-5}$, но она представляет уже "готовое" значение, а не вычисляемое выражение.



## Диапазон положительных чисел типа Float64

Примерно диапазон значений типа Float64:
$$
мантисса*10^{-308}...мантисса*10^{308}
$$

причем под **мантиссой** здесь понимается **нормализованная** мантисса.

Более точная верхняя граница диапазона значений типа Float64:
```julia
julia> 2.0^1023
8.98846567431158e307

julia> 2.0^1024
Inf
```
Здесь при порядках выше 1023 возникает эффект **переполнения поряка**

Более точная нижняя граница диапазона значений типа Float64:
```julia
julia> 2.0^-1023
1.1125369292536007e-308

julia> 2.0^-1024
5.562684646268003e-309

julia> 2.0^-1050
8.289046e-317

julia> 2.0^-1074
5.0e-324

julia> 2.0^-1075
0.0
```

Здесь, при двоичных порядках меньше -1023, наблюдается **эффект денормализации** мантиссы

## Неравномерная шкала машинных чисел с плавающей точкой

- "Машинный ноль"
- "машинное эпсилон"
- Абсолютная и относительная погрешность представления вещественного числа значением с плавающей точкой. 
- Функции eps
- Функция isapprox (операция ≈)

## Погрешности арифметики с плавающей точкой

Несмотря на кажущуюся избыточную точность представления чисел, имеющейся длины мантиссы иногда не хватает. Дело в том, что погрешности вычислений могут накапливаться.

Арифметика с плавающей точко сопряжена со следующими неприятными явлениями

- **Потеря точности** - это когда результат операции теряет некоторые младшие цифры мантиссы

- **Денормализация** - возникает, когда отрицательный порядок достигает своего максимального по модулю предельного значения (примерно $10^{-307}$), но требуется записать результат, порядок которого меньше этого предельного значения. Это возможно только за счет сдвига мантиссы вправо (с потререй её младших значаших цифр).

- В пределе, когда при возникновении эффекта денормализации мантиссы, окажутся потерянными все ее значащие цифры, происходит эффек, называемый **потерей порядка**. Подучаемый при этом результат не отличим от нуля, и он называется машинным нулем. Граница машинного нуля - примерно $10^{-324}$

- **Переполнение порядка** - это эффект, возникающий при превышении у результата максимального положительного порядка (примерно $10^{307}$). Получающееся в этом случае значение интерпретируется как "бесконечность" (`Inf`).

- `Inf+Inf` \to `Inf`, `положительное_число*Inf = Inf`, `отрицательное_число*Inf = -Inf`, `0*Inf = NaN` (это еще одно значение с плавающей точкой, которое интерпретируется как "не числовое значение"), `1/0=Inf`, `1/Inf=0`, `0/0=NaN`
(значения `Inf` и `NaN` имеют свои уникальные `64` битные коды)

Чтобы понимать технические причины возникновения всех этих эффектов, нужно разобраться с тем, что происходит при выполнении арифметических опереаций.

Так, при выполнении сложения двух положительных значений с плавающей точкой выполняются следующие три действия.

1. Выравнивание порядков: сначала определяется число с меньшим порядком, а затем в цикле его порядок увеличивается на единицу, а мантисса делится на 2 до тех пор, пока порядки двух чисел не сравняются. При сдвигах вправо младшие разряды теряются, и если эти потерянные разряды не нулевые, то произойдет **потеря точности**.

2. Сложение мантисс.

3. Нормализация мантиссы: если после сложения мантисса результата стала равна или превысила двойку, то порядок результата должен уиеличен на единицу, а мантисса поделена на 2 (т.е. сдвинута на один разряд вправо). В результате этого мантисса попадёт в требуемый интервал `1 < m < 2`, но при этом возможна **потеря точности** (если только потерянный при сдвиге разряд не был нулевым), а также **переполнение** (если после прибавления единицы порядок превысит предельное значение).

Аппаратно деление на `2` осуществлянтся путем простого сдвига двоичного кода мантиссы вправо, поэтому данная операция выполняется быстро.

Вычитание производится аналогичным образом. 

При умножении порядки складываются, а мантиссы перемножаются как целые числа, после чего у результата правые разряды отбрасываются. 

В результате сложения порядков может происходить как "переполнение порядка" (если порядки положительные), так и "исчезновение порядка" (если порядки отрицательные).

Ситуация при выполнении деления аналогична.

Особенно следует отметить ситуацию, возникающую при **сложении двух очень близких по абсолютной величине величин, но противоположных по знаку, или при вычитании очень близких величин одного знака**. Если порядки соответствующих операндов будут равны, а мантиссы - приблизительно равны, то результирующая мантисса после нормализации окажется много короче 53 бит. А это означает, что **относительная    погрешность результата такой операции может значительно увеличиться**.

## О назначении более коротких типов с плавающей точкой

Типы `Float16`, `Float32` имеют меньший диапазон порядков и более короткую мантиссу, но аппаратно операции все-равно выполяются с `Float64` (если только речь не идет о видеокартах, там может использоваться более коротий тип `Float32`).

Эти типы позволяют просто более компактно хранить в памяти очень большие объемы числовых данных (например, изображения).

## Тип BigFloat
Этот тип позволяет вычислять с мантиссой произвольной (произвольно установленной) длины.
Ооднако операции с этим типом реализованы программно, поэтому они намного менее производительны по сравнению с аппаратно реализованной арифметикой с плавающей точкой. 

Функции, обеспечивающие контроль длины мантиссы при работе с типом BigFloat: `precision`, `setprecision`.

## Некоторые примеры особенностей арифметики с плавающей точкой

1. Положим
```julia
a = sqrt(2)
e = eps()/2
```
тогда

```julia
(a+e)+e != a+(e+e) # true
```
2. Положим также 
```julia
b = a+e
```
тогда
```julia
b-a != e # true
```

## Регламентирующие правила для машинной арифметики с плавающей точкой

Фоматы представления чисел с плавающей и правила для машинных операций с этими числами регламентированы стандартом IEEE (https://ru.wikipedia.org/wiki/Институт_инженеров_электротехники_и_электроники).

## Функция set_zero_subnormales

**Денормализованные** числа называют ещё **субнормальными** числами. В языке Julia имеется возможность интерпретировать (или не интерпретировать) такие числа, как нули с помощью специальной функции `set_zero_subnormales`. Это может существенно влиять на производительность кода (см. официальную документацию).

-------------------------------------------

## Алгоритм быстрого возведения в степень

Пусть при некотором натуральном $n$ требуется вычислить $a^n$.

Наивный подход к этому вышлядит так
```julia
k = n; p = 1
#ИНВАРИАНТ: p == a^(n-k)
while k>0
    p *= a
    k -= 1
end
# k==0 => p=a^n
```

Асимптотическая оценка сложности этого алгоритма - $O(n)$.

Однако, если число n есть некоторая степень 2, т.е. $n=2^m$, то можно предложить следующий алгоритм с оценкой сложности  $O(\log_2 n) = m$

```julia
k = n; p = a
#ИНВАРИАНТ: p^k == a^n
while k>1
    k /=2
    p = p*p # - это преобразование следует из инварианта
end
# k==1 => p=a^n
```
A возможен ли такой же быстрый алгоритм, если n не есть степень двойки? Ответ - да, возможен. В самом деле, в начале, как и прежде, положим `k=n`, и на очередном шаге алгоритма, при условии, если `k` - четное, то выполним один шаг предыдущего алгоритма, т.е. положим `k=k/2; p=p*p`, а в противном случае, если `k` - не четное, то положим `k = k-1` и тут надо ещё сделать как-то так, чтобы в последствии окончательный результат домножился на `a`. Реализация этой идеи приводит к следующему алгоритму

```julia
k=n; p=a; t=1
#ИНВАРИАНТ: p^k * t == a^n
while k>0
    if iseven(k)
        k /= 2 # - преобразование, направленное в сторону завершеня цикла,
        p *= p # тогда следующее преобразование следует из инварианта
    else
        k -= 1 # - преобразование, направленное в сторону завершеня цикла,
        t *= p # тогда следующее преобразование следует из инварианта
    end
end
# k == 0 => t = a^n
```
Поскольку преобразование `k=k/2` будет случаться здесь не реже чем через раз, то оценка сложности получается - $O(\log n)$.

## Алгоритм быстрого вычисления n-го числа Фибонвччи

Рассмотрим еще раз задачу вычисления n-го числа последовательности Фибоначчи: $F_0=0, \ F_1=1, \ F_{k+1}=F_k+F_{k-1} \ \forall k> 1$

Все рассматривавшиеся ранее алгоритмы вычисления n-го члена этой последовательности имели оценку сложности $O(n)$. А возможен ли здесь более быстрый алгоритм, например, с оценкой $O(\log n)$? Оказывается, что возможен.

Во-первых, существует так называемая формула Бине

$$
F_n = \frac{1}{\sqrt 5}\Bigg(\Big(\frac{1+\sqrt 5}{2}\Big)^n-\Big(\frac{1-\sqrt 5}{2}\Big)^n\Bigg)
$$
не будем останавливаться на выводе этой формулы, она достаточно известная.

В принципе, эта формула сводит вычисление `n`-го числа Фибоначчи к задаче возведения некоторого числа в `n`-ую степень, а эта задача имеет требуемое решение. Однако, дважды возводить в степень придется иррациональное число, которое в арифметике с плавающей точкой неизбежно будет представленно с некоторой погрешностью. В результате и вычисляемое число Фибоначчи может содержать неверные цифры, во всяком случае это верно при больших `n` (а именно для больших `n` и важна логарифмическая сложность). Таким образом, основанный на формуле Бине алгоритм, получится не вполне удовлетворительным.

Выход, однако, имеется благодаря следующему факту

$$
\begin{bmatrix}
F_{n} \\ F_{n-1}
\end{bmatrix} = \begin{bmatrix}
    1 & 1 \\ 1 &0
\end{bmatrix} \begin{bmatrix}
F_{n-1} \\ F_{n-2}
\end{bmatrix} =...= \begin{bmatrix}
    1 & 1 \\ 1 &0
\end{bmatrix}^n \begin{bmatrix}
1 \\ 0
\end{bmatrix}
$$

Таким образом, задача свелась к возведению в `n`-ю степень матрицы `2` на `2`, для чего у нас имеется быстрый алгоритм (возводить в степень не обязательно число, можно, например, и - матрицу).

## Алгоритм вычисления логарифма с заданной точностью

Пусть требуется построить алгоритм приближенного вычисления логарифма произвольно заданного числа `x` по основанию `a`. Для определённости будем считать, что основание $a>1$.
И так, требуется вычислить
$$
y=\log_a x
$$

с абсолютной погрешностью, не превосходящей произвольно заданного $\varepsilon >0$.

Пусть $\tilde y=y+\Delta$ - это искомое значение, где $\Delta$- это величина погрешности, т.е. $|\Delta| \le \varepsilon$. Тогда имеем

$$
x = a^y=a^{\tilde y - \Delta} =a^{\tilde y}a^{-\Delta}=a^{\tilde y}z^t
$$
где $z^t=a^{-\Delta}$, $z, \ t$ - две новые переменные, значения котрых потребуется выбрать такими, чтобы обеспечить требование $|\Delta|\le \varepsilon$.

Логарифмируя равенство $z^t=a^{-\Delta}$, получим
$|\Delta|=|t||\log_a z| \le \varepsilon$. Для достижения последненго неравенства достаточно обеспечить, чтобы было $|t| \le \varepsilon$ и $|\log_a z| \le 1$. Т.к. по предположению $a>1$, то второе неравенство означает, что $1/a \le z \le a$.

Таким образом, получаем следующий алгоритм

```julia
z=x; t=1; y=0
#ИНВАРИАНТ:  x = z^t * a^y
while z < 1/a || z > a || t > ε 
    if z < 1/a
        z *= a # это перобразование направлено на достижения условия окончания цикла
        y += t # тогда необходимрсть этого преобразования следует из инварианта цикла
    elseif z > a
        z /= a # это перобразование направлено на достижения условия окончания цикла
        y -= t # тогда необходимрсть этого преобразования следует из инварианта цикла
    elseif t > ε
        t /= 2 # это перобразование направлено на достижения условия окончания цикла
        z *= z # тогда необходимрсть этого преобразования следует из инварианта цикла
    end
end
# y - искомое приближенное значение
```

**Замечание**

С формальной точки зрения может показаться, что здесь безразлично, в каком именно порядке проверять условия в теле цикла. Т.е. может показаться, что условие `t > ε` можно было бы проверять первым, однако это не так. В самом деле, если предварительно не добитьться "попадания" переменной `z` в целевой интервал, то при слишком больших значениях этой переменной повторение преобразования `z=z*z` очень быстро приведет к переполнению порядка, а если, наоборот, значение `z` будет слишком мало, то это же преобразование очень быстро приведет к исчезновению порядка. В любом случае желаемый ответ получен не будет.

---------------------------------

**ДОПОЛНИТЕЛЬНЫЙ ТЕОРЕТИЧЕСКИЙ МАТЕРИАЛ ДЛЯ ПРАКТИКИ**


---------------------------------

## 1. Приближенное решение нелинейного уравнения методом деления отрезка пополам

$$
\text{f}(x)=0
$$
- $\text{f} \in C[a;b]$ (функция непрерывная);

- на отрезке локализации $[a;b]$ уравнение имеет единственный корень;
- $\text{f}(a)\text{f}(b)<0$, т.е. на концах отрезка локализации знчения функция имеет противоположные знаки.

```julia
function bisection(f::Function, a, b, epsilon)
    @assert f(a)*f(b) < 0 
    @assert a < b
    f_a = f(a)
    #ИНВАРИАНТ: f_a*f(b) < 0
    while b-a > epsilon
        t = (a+b)/2
        f_t = f(t)
        if f_t == 0
            return t
        elseif f_a*f_t < 0
            b=t
        else
            a, f_a = t, f_t
        end
    return (a+b)/2
end
```
Следующий рисунок поясняет идею данного алгоритма.

![Риснок](P2_bisection.png)

**Задание.** С помощью функции `bisection` решить уравнение $\cos x=x$ с какой-либо роизвольно заданной точностью.


## 2. Метод Ньютона приближенного решения нелинейного уравнения

$$
f(x)=0, \ \ \ f \in C^1[a;b]
$$

Пусть $x_0$ - некоторое выбранноге начальное приближение.

Как можно понять из приведенного ниже рисунка, поясняющий рассматриваемый здесь алгоритм Ньютона, выбор начального приближения $x_0$ критически важен для правильной работы данного алгоритма. Этот алгоритм состоит итерационном процессе, на кждом шаге которог получается очередное, более точное приближение искомого корня уравнения. 

Формула для получения очередного приближения получается следующим образом.

Пусть после $k$ итераций получено очередное приближенное значение корня $x_k$. Тогда, воспользовавшись формулой конечных приращений Лагранжа (разложением Тейлора) исходное нелинейное уравнение можно переписать в виде

$$
f(x)=f(x_{k})+f'(x_k)(x-x_k) + o(|x-x_k|)= 0
$$

Отбрасывая в левой части этого уравнения "малый" член, получим линейную аппроксимацию исходного уравнения

$$
f(x_{k})+f'(x_k)(x_{k+1}-x_k) = 0
$$

(левой части этого уранения стоит $f(x_k)$ плюс дифференциал функции $f$ в точке $x_k$).

Графическая иллюстрация этого метода представлена на следующем рисунке.

![Метод касательных](P2_newton.png)

Из рисунка ясно, почему метод Ньютона часто называют также методом касательных.

Решая это линейное уравнение относительно $x$, получим формулу вычисления очередного $(k+1)$-приближения
$$
x_{k+1}=x_k-\frac{f(x_k)}{f'(x_k)}, \ \ \ k=0,1,2,....
$$
где предполагается, конечно, что $f'(x_k) \ne 0$.

Итерируя эту формулу, получим последовательность приближений $x_0,x_1,x_2,....$, кототорая при определенных условиях может сходиться к искомому корню. Но может и не сходиться в случае, если начальное приближение $x_0$ было выбрано не удачно. 

Поэтому, во-первых, для останова алгоритма требуется задаться некоторой величиной $\varepsilon > 0$, и при достижении условия $|x_{k+1}-x_k| \le 0$ прекратить итерации, приняв за приближенное значение корня велмчину $x_{k+1}$. 

Во-вторых, на случай, если выбор начального приближения $x_0$ оказался неудачным, и сходимости нет (или она слишком медленная), надо задать некоторое максимальное число итераций, превышение которого должно приводить к прерыванию цикла с выводом соответствующего передупреждения.

Для вывода предупреждения в языке имеется специальный макрос:
```julia
@warn("Текст сообщения")
```
который и используется в следующем коде.

```julia
"""
newton(r::Function, x; epsilon = 1e-8, num_max = 10)

- возвращает приближенное решение уравнения вида f(x)=0

При этом предполагается, что получаемая через параметр функция r(x) возвращает решение уравнения: (f'(x))*dx=-f(x) относительно dx

"""
function newton(r::Function, x; epsilon = 1e-8, num_max = 10)
    dx = r(x); x += dx; k=1
    while abs(dx) > epsilon && k < num_max
        dx = r(x); x += dx; k += 1
    end
    abs(dx) > epsilon && @warn("Требуемая точность не достигнута")
    return x
end
```

**Задания**

- с помощью функции newton приближенно рещить уравнение
  $\cos x = x$
- с помощью функции newton найти приближеннное значение какого-либо вещественного корня уравнения
 $P_n(x)=x$
задавшись соответсвующим начальным приближение, где $P_n$ - это некоторый многочлен, представленный значением типа `Polynomial` (предполагается, что для этого типа определена функция, реализованная по схеме Горнера, и возвращающая кортеж заначений соответсвующего многочлена и его производной в заданной точке).


## 3. Вычисление комплексных корней методом Ньютона

Метод Ньютона может быть использован не только для приближенного вычисления вещественных корней функции, но и для приближенного вычисления её комплексных корней. Для этого функция должна быть представима рядом Тейлора (такие функции называются аналитическими). В частности, функция может представлять собой многочлен.

При этом, в случае комплексной переменной определение самого понятия производной и правила дифференцирования, по форме, остаются теми же, что и для вещественной переменной.

Пусть $f: \mathbb C \to \mathbb C$, и пусть эта функция непрерывна на $\mathbb C$. Тогда эта функция называется дифференцируемой на $\mathbb C$, если в каждой точке комплексной плоскости существует предел

$$
f'(z) = \lim_{\Delta z \to 0} \frac{f(z+\Delta z)-f(z)}{\Delta z}
$$

В таком случая этот предел называется производной аналитической функции комплексной переменной $f(z)$.

Например, $(z^n)'=nz^{n-1}$.

Поэтому полученная выше итерационная формула метода Ньютона годится и для приближенного вычисления комплексных корней многочленов.

## 4. Решение систем нелинейных уравнений методом Ньютона

Рассмотрим систему двух уравнений с двумя неизвестными общего вида
$$
\begin{cases}
f^1(x^1,x^2) = 0 \\
f^2(x^1,x^2) = 0
\end{cases}
$$
(здесь нам удобно будет использовать верхние индексы, вместо, может быть, более привычных нижних), где предполагается, функции $f^1(x^1,x^2)$, $f^2(x^1,x^2)$ обладают достаточной гладкостью.

Это уравнение можно записать в векторной записи, сразу обобщив его на случай $n$ уравнений с $n$ неизвестными,
$$
f(x) = 0
$$
где $f: \mathbb R^n \to \mathbb R^n, x=[x^1,...,x^n]$. При $n=2$ получим рассматриваемый нами частный случай $f(x)=[f^1(x), f^2(x)]$, где $x=[x^1,x^2]$.

Тогда использованная нами ранее формула конечных приращений Лагранжа

$$
f(x)=f(x_{k})+f'(x_k)(x-x_k) + o(|x-x_k|)= 0
$$

по-прежнему остается в силе. С той лишь разницей, что теперь под производной вектор-функции $f$ от векторного аргумента $x$ следует понимать матрицу, составленнную из частных производных, которая называется матрицей Якоби. Например, при $n=2$ матрица Якоби имеет вид:

$$
f'(x)=\begin{bmatrix}
\frac{\partial f^1(x)}{\partial x^1} & \frac{\partial f^1(x)}{\partial x^2} \\ \\
\frac{\partial f^2(x)}{\partial x^1} & \frac{\partial f^2(x)}{\partial x^2} 
\end{bmatrix}
$$

С учетом этого, итерационную формулу придется записать в виде 

$$
x_{k+1}=x_k-(f'(x_k))^{-1}f(x_k), \ \ \ k=0,1,2,....
$$
где $(f'(x_k))^{-1}$ - матрица, обратная к матрице Якоби $f'(x_k)$. Причем в таком виде эта формула верна и для рассмотренного ранее одномерного случая при $n=1$. 

Кроме того, под $|x-x_k|$ в общем случае надо понимать норму вектора $x-x_k$. Вообще, в $n$-мерном пространстве нормы бывают разные. Известная из линейной алгебры евклидова норма - это только один частный пример нормы. В нашем случае удобно будет считать, что $|x-x_k| = \max{\{|x^1-x^1_k|,..., |x^n-x^n_k|\}}$, но, в принципе, здесь можно было бы использовать и евклидову норму.

Исходя из этого, чтобы функцию `newton` можно было бы применять также и для решения систем уравнений, в написанном выше коде этой функции выражение `abs(dx)` следует заменить на `maximum(abs.(dx))`. Ничего больше в этом коде изменять не придется.

Но при этом, в общем случае системы $n$-уравнений с $n$ неизвестными, под функциональным параметром `r` надо будет уже понимать функцию, вычисляющую $n$-мерный вектор $(f'(x_k))^{-1}f(x_k)$.

Здесь важно еще раз отметить то, что реализованная нами функция `newton` оказалась весьма универсальной (обобщённой), если только правильно понимать, как ей пользоваться в различных ситуациях.

**Задание** 

Найти приближенные решения следующей системы уравнений, воспользовавшись функцией `newton`.

$$
\begin{cases}
x^2+y^2=1 \\
x^3y=1
\end{cases}
$$

Подходящее начальное приближение для каждого из 4-х имеющихся у этой системы решений подобрать самостоятельно (для этого, возможно, придётся немного поэкспериментировать).

Для обращения матрицы Якоби можно было бы, например, воспользоваться встроенной функцией `inv`.

Однако с вычислительной точки зрения более экономичным будет другой способ, не предполагающий явное обращение матрицы Якоби. 

Обозначим $\Delta x_k = x_{k+1}-x_k$ (именно эту величину и вычисляет функция `r`, передаваемая в виде параметра в функцию `newton`), тогда
$$
\Delta x_{k}=-(f'(x_k))^{-1}f(x_k)
$$
или

$$
f'(x_k)\Delta x_{k}=-f(x_k)
$$
т.е. приходим к СЛАУ относительно $\Delta x_k$ с матрицей $f'(x_k)$ и столбцом свободных членов $-f(x_k)$. 

Для записи решения системы вида $Ax=b$ в языке Julia предусмотрена операция "обратного" деления:

$$
x = A \backslash b
$$
\- читается: "$b$ делить на $A$ слева"
(это обозначение соответствует как бы умножению на обратную матрицу слева).

На самом деле, данная операция сводится к вызову процедуры, решающей СЛАУ методом Жордана-Гаусса. 

Как уже отмечалось, с вычислительной точки зрения решение СЛАУ менее затратно, по сравнению с обращением матрицы (и последующим умножением ее на вектор). Однако разница в этом будет заметной только при большом числе уравнений и переменных в системе.

**Замечание.** Если бы требовалось решить не систему вида $A х=b$, а систему вида $xA=b$, то на языке Julia ее решение записывалось бы уже с использованием операции "прямого" деления: $x=b/A$  - читается: "$b$ делить на $A$ справа" (это обозначение соответствует как бы умножению на обратную матрицу справа).

